So I've used the pollution.csv as a dataset which around 43k rows.
First it will create dataset.csv from pollution.csv and feed it in lstm network.
lstm_reg.py will train network, which I've already did and save the model in same folder.
predict.py will predict the humidity, temp, and ppm for next 100 hours by giving 100 input rows.
Train, Validation and test data is splitted in 30k, 5k, and remaining respectively.
lstm model is defind in lstm_model.py

You need keras, tensorflow, pandas, sklearn. (if not installed the you have to install all these)

To run:
FILE_1: lstm_reg.py (run again, to get the graphs)
python lstm_reg.py

FILE_2: predict.py
python predict.py

to see the graphs: open another cmd in same folder and copt paste in cmd and run then it shows the link and then go to that link in browser. you will get those graph
tensorboard --logdir='./tensorboard'